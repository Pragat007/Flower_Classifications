# -*- coding: utf-8 -*-
"""Flower classification ResNet

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BmksdQYb1VA0UbfTk86xjOaFu549c2NY
"""

#Import above mentioned libraries.
import numpy as np
import matplotlib.pyplot as plt
import os
import PIL
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout
from keras.optimizers import Adam

from pathlib import Path

# dataset_url = link of the dataset
dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = Path(data_dir)

img_count=len(list(data_dir.glob('*/*.jpg')))
print(img_count)

rose=list(data_dir.glob('roses/*'))
PIL.Image.open(str(rose[0]))

PIL.Image.open(str(rose[2]))

tulips=list(data_dir.glob('tulips/*'))
PIL.Image.open(str(tulips[0]))

batch_size = 32
img_height = 180
img_width = 180

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print(class_names)

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(6):
    ax = plt.subplot(3, 3, i +1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

for image_batch, labels_batch in train_ds:
  print(image_batch.shape)
  print(labels_batch.shape)
  break

import tensorflow as tf
from tensorflow.keras import layers

resnet_model=Sequential()
pretrained_model=tf.keras.applications.ResNet50(include_top=False,input_shape=(img_height, img_width,3),pooling='avg',classes=5,weights='imagenet')
for layer in pretrained_model.layers:
  layer.trainable=False
resnet_model.add(pretrained_model)

resnet_model.add(Flatten())
resnet_model.add(Dense(512,activation='relu'))
resnet_model.add(Dense(5,activation='softmax'))

resnet_model.compile(optimizer=Adam(learning_rate=0.001),
                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])

resnet_model.summary()

epochs=10
history=resnet_model.fit(train_ds,validation_data=val_ds,epochs=epochs)

# After training your model locally
resnet_model.save('model.h5')



fig1=plt.gcf()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.axis(ymin=0.4,ymax=1)
plt.grid()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train','validation'])
plt.show()

"""# **Visulaizing image of rose and tulips using cv2**"""

import cv2
roses=list(data_dir.glob('roses/*'))
image=cv2.imread(str(roses[0]))
image_resized=cv2.resize(image,(img_height,img_width))
image1=np.expand_dims(image_resized,axis=0)

PIL.Image.open(str(roses[0]))

tulip=list(data_dir.glob('tulips/*'))
image=cv2.imread(str(tulip[1]))
image_resized=cv2.resize(image,(img_height,img_width))
image2=np.expand_dims(image_resized,axis=0)

PIL.Image.open(str(tulip[0]))

pre1=resnet_model.predict(image1)
pre2=resnet_model.predict(image2)

output_class=class_names[np.argmax(pre1)]
print("The Predicted class is ",output_class)

output_class2=class_names[np.argmax(pre2)]
print("The Predicted class is ",output_class2)



!pip install gradio

!pip uninstall gradio==3.15.0 -y
!pip install gradio==3.9.0

!pip install -U httpcore

import numpy as np
import gradio as gr
from tensorflow.keras.models import load_model
from PIL import Image

# Load the pre-trained model
resnet_model = load_model('model.h5')

class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']

def predict_image(img):
    # Ensure the image is resized to 180x180 pixels
    img_resized = np.array(Image.fromarray(img).resize((180, 180)).convert('RGB'))

    # Reshape the image to match the input shape expected by the model
    img_4d = img_resized.reshape(-1, 180, 180, 3)

    prediction = resnet_model.predict(img_4d)[0]

    return {class_names[i]: float(prediction[i]) for i in range(5)}

# Define the Gradio interface using the older version
inputs = gr.inputs.Image(shape=(180, 180))  # Ensure the image has the correct shape
outputs = gr.outputs.Label(num_top_classes=5)

iface = gr.Interface(
    fn=predict_image,
    inputs=inputs,
    outputs=outputs
)

iface.launch(debug=True, share=True)

